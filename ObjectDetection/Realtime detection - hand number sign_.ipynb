{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.;C:\\\\Users\\\\Playdata\\\\ObjectDetection\\\\TF_oda2\\\\models;C:\\\\Users\\\\Playdata\\\\ObjectDetection\\\\TF_oda2\\\\models\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYTHONPATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util, config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_CONFIG_PATH = os.path.join('model', 'pipeline.config')\n",
    "CHECK_POINT_PATH = os.path.join('model', 'checkpoint', 'ckpt-51')\n",
    "LABEL_MAP_FILE_PATH = os.path.join('labelmap', 'label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2a6782ba488>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipline.config에 맞춰서 추출한 모델을 바탕으로 모델을 생성 \n",
    "\n",
    "# pipeline.config를 조회\n",
    "config = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH)\n",
    "# pipeline.config의 model설정 정보를 넣어서 모델생성\n",
    "detection_model = model_builder.build(model_config=config['model'], is_training=False)\n",
    "\n",
    "# 모델에 학습시킨 checkpoint(weight)를 주입\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(CHECK_POINT_PATH).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detection을 실행하는 함수\n",
    "\n",
    "# 순전파 처리 함수에 @tf.function decorator를 선언하면 실행 속도가 빨라진다.\n",
    "@tf.function\n",
    "def detect_func(image):\n",
    "    \"\"\"\n",
    "    매개변수로 object detection을 수행할 대상 image(Tensor)를 받아서 detection 처리.\n",
    "    1. preprocessing(전처리): resize, normalization 작업\n",
    "    2. detection(inference-추론)\n",
    "    3. detection결과를 post processing : Non Maxinum Suppression\n",
    "    4. post processing한 결과를 반환.\n",
    "    \"\"\"\n",
    "    # 1 preprocessing\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    # 2. 추론\n",
    "    predict_dict = detection_model.predict(image, shapes)\n",
    "    # 3. post processing\n",
    "    result = detection_model.postprocess(predict_dict, shapes)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'id': 1, 'name': 'one'},\n",
       " 2: {'id': 2, 'name': 'two'},\n",
       " 3: {'id': 3, 'name': 'three'},\n",
       " 4: {'id': 4, 'name': 'four'},\n",
       " 5: {'id': 5, 'name': 'five'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(LABEL_MAP_FILE_PATH)\n",
    "print(type(category_index))\n",
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 웹캠으로 부터 이미지를 받아서 추론한 결과를 화면에 보여주기.\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(cap.isOpened())\n",
    "# 웹캠의 WIDTH/HEIGHT 조회\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read() #한 frame 읽기.\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"이미지를 읽지 못함\")\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1) #좌우 반전\n",
    "    \n",
    "    #BGR=>RGB (모델이 학습할 때 RGB 모드로 학습했기 때문에 같은 형식으로 변환)\n",
    "    image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    #0번 축을 늘린다. Tensor로 변환\n",
    "    input_tensor = tf.convert_to_tensor(image_np[np.newaxis, ...], dtype=tf.float32)\n",
    "    # 추론\n",
    "    post_detection = detect_func(input_tensor) #전처리->추론->후처리\n",
    "    \n",
    "    num_detections = int(post_detection.pop('num_detections'))\n",
    "    # 추론한 결과들을 num_detections 개수(detection한 물체의 개수) 만큼의 값만 남긴다. 결과가 Tensor로 반환되는 것을 ndarray로 변환.\n",
    "    detections = {key:value[0, :num_detections].numpy() for key, value in post_detection.items()}\n",
    "\n",
    "    # 새로 구성한 결과 dictionary(detections)에 num_detections 값을 추가.\n",
    "    detections['num_detections'] = num_detections\n",
    "    # detection_classes 는 검출한 box의 class 값을 label encoding 된 값으로 가진다. float32로 반환되는 것을 int로 변환 처리.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    \n",
    "    MIN_CONF_THRESH = 0.7 # 물체가 있을 Confidence score가 0.5 이상인 bounding box만 나오도록 하겠다.\n",
    "    image_np_with_detection = image_np.copy()  #detection한 원본 이미지의 카피본을 생성.\n",
    "    img = viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                    image_np_with_detection, #추론한 원본이미지,\n",
    "                    detections['detection_boxes'], #bounding box 좌표\n",
    "                    detections['detection_classes'] + 1, #bouding box내의 물체 index (class확률에서 0은 첫번째 label, label map의 id는 1부터 시작 하기 때문에 +1)\n",
    "                    detections['detection_scores'], #bounidng box내에 물체가 있을 확률(confidence score)\n",
    "                    category_index, \n",
    "                    use_normalized_coordinates=True, #bounding box의 좌표들이 normalize되었는지 여부\n",
    "                    max_boxes_to_draw=100, # 최대 몇개 박스를 칠 것인지 (기본: 20)\n",
    "                    min_score_thresh=MIN_CONF_THRESH)  # Confidence socre가 얼마 이상인 bounding box만 나오도록 하겠다.\n",
    "    \n",
    "    # 결과 image를 RGB => BGR\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    print(img.shape)\n",
    "    break\n",
    "    #화면에 출력\n",
    "    cv2.imshow('frame', img)\n",
    "    if cv2.waitKey(1) > 0: #아무키나 입력하면\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post processing 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('one.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = img[np.newaxis, ...]\n",
    "input_tensor = tf.convert_to_tensor(img, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_detection = detect_func(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['detection_boxes', 'detection_scores', 'detection_classes', 'num_detections', 'raw_detection_boxes', 'raw_detection_scores', 'detection_multiclass_scores', 'detection_anchor_indices'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['num_detections'].numpy() #Tensor => ndarray\n",
    "# num_detections: 후처리로 최종 결과로 나온 bounding box의 개수. \n",
    "# 전체 bounding box에서 confidence score 순으로 내림 차순한 뒤 NMS 을 거쳐서 최종적으로 남은 bounding box의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 100, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['detection_boxes'].shape\n",
    "# [1, 100, 4] => [추론한이미지개수, num_detections, 좌표(x,y,w,h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 100])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bbox에 물체가 있을 확률 = confidence score\n",
    "post_detection['detection_scores'].shape\n",
    "# [1, 100], [추론한이미지개수, num_detections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.99999934, 0.02000004, 0.01957524, 0.01314369, 0.01004648,\n",
       "       0.00982314, 0.00981891, 0.00946924, 0.00946558, 0.00924185],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['detection_scores'][0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.6061671 , 0.40268105, 0.97964144, 0.5990967 ], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['detection_boxes'][0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
       "array([[0.99999934, 0.02000004, 0.01957524, 0.01314369, 0.01004648,\n",
       "        0.00982314, 0.00981891, 0.00946924, 0.00946558, 0.00924185,\n",
       "        0.00861913, 0.00804833, 0.00766084, 0.00732458, 0.0073235 ,\n",
       "        0.00729269, 0.00718403, 0.00665718, 0.00665098, 0.00640824,\n",
       "        0.00625852, 0.00610211, 0.00593981, 0.00584751, 0.00546545,\n",
       "        0.005299  , 0.00509086, 0.00506631, 0.00506613, 0.0050447 ,\n",
       "        0.00500393, 0.00495923, 0.00493613, 0.00493127, 0.00485682,\n",
       "        0.00482705, 0.00470507, 0.00462821, 0.00452715, 0.00442025,\n",
       "        0.00435778, 0.00427103, 0.00426495, 0.00413018, 0.00411677,\n",
       "        0.00411001, 0.00406948, 0.00404009, 0.00403646, 0.00398517,\n",
       "        0.00397146, 0.00394303, 0.00394279, 0.00392681, 0.00380638,\n",
       "        0.00378749, 0.00370955, 0.00363976, 0.00363174, 0.00363004,\n",
       "        0.00358856, 0.00358668, 0.00356436, 0.00356168, 0.00354788,\n",
       "        0.00352094, 0.00346696, 0.00344554, 0.00343415, 0.0034281 ,\n",
       "        0.00342801, 0.00342631, 0.00342333, 0.00341591, 0.00339058,\n",
       "        0.00338727, 0.0033533 , 0.0033468 , 0.00334066, 0.00333408,\n",
       "        0.00333393, 0.00333303, 0.00331962, 0.00330675, 0.00327498,\n",
       "        0.00326142, 0.00326055, 0.00323915, 0.00323477, 0.0032326 ,\n",
       "        0.0032059 , 0.00319481, 0.00318724, 0.00317916, 0.00317198,\n",
       "        0.00317076, 0.00315544, 0.00315496, 0.00315306, 0.00313634]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['detection_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['detection_classes'][0, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 100, 6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 class 별 확률\n",
    "post_detection['detection_multiclass_scores'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
       "array([1.3113618e-03, 9.9999934e-01, 1.1473298e-03, 1.3917685e-03,\n",
       "       1.7806906e-08, 5.2607059e-04], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['detection_multiclass_scores'][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12804, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['raw_detection_boxes'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
